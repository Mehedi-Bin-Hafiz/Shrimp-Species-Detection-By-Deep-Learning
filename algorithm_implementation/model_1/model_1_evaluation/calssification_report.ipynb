{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c5d1b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "from keras.preprocessing.image import load_img\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from matplotlib import  pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "from skimage import io\n",
    "import time\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras \n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "model = keras.models.load_model('../Shrimp_model_1.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b2e03a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bagda', 'deshi', 'golda', 'horina']\n",
      "total class  4\n"
     ]
    }
   ],
   "source": [
    "testing_dataset = 'F:\\\\Research database\\\\Shrimp Recognition\\\\testing\\\\' \n",
    "main_classes = os.listdir(testing_dataset) \n",
    "print(main_classes)\n",
    "len_main_classes = len(main_classes)\n",
    "print('total class ',len_main_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3de270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images prediction completed. Time taken 63.68 s\n",
      "200  images prediction completed. Time taken 43.56 s\n",
      "300  images prediction completed. Time taken 72.46 s\n",
      "400  images prediction completed. Time taken 72.81 s\n",
      "500  images prediction completed. Time taken 102.38 s\n",
      "600  images prediction completed. Time taken 34.37 s\n",
      "700  images prediction completed. Time taken 115.20 s\n",
      "800  images prediction completed. Time taken 112.27 s\n",
      "900  images prediction completed. Time taken 115.95 s\n",
      "1000  images prediction completed. Time taken 113.73 s\n",
      "1100  images prediction completed. Time taken 115.87 s\n",
      "1200  images prediction completed. Time taken 91.99 s\n",
      "1300  images prediction completed. Time taken 68.51 s\n",
      "1400  images prediction completed. Time taken 111.82 s\n",
      "1500  images prediction completed. Time taken 58.50 s\n",
      "1600  images prediction completed. Time taken 115.60 s\n",
      "1700  images prediction completed. Time taken 56.92 s\n",
      "1800  images prediction completed. Time taken 36.85 s\n",
      "1900  images prediction completed. Time taken 35.89 s\n",
      "2000  images prediction completed. Time taken 33.27 s\n",
      "2100  images prediction completed. Time taken 35.62 s\n",
      "2200  images prediction completed. Time taken 16.05 s\n",
      "2300  images prediction completed. Time taken 23.00 s\n",
      "2400  images prediction completed. Time taken 33.21 s\n",
      "2500  images prediction completed. Time taken 29.50 s\n",
      "2600  images prediction completed. Time taken 23.11 s\n",
      "2700  images prediction completed. Time taken 25.79 s\n",
      "2800  images prediction completed. Time taken 33.19 s\n",
      "2900  images prediction completed. Time taken 39.92 s\n",
      "3000  images prediction completed. Time taken 31.95 s\n",
      "3100  images prediction completed. Time taken 29.67 s\n"
     ]
    }
   ],
   "source": [
    "real_calss_list = list()\n",
    "prediction_class_list = list()\n",
    "image_classes = os.listdir(testing_dataset)\n",
    "count = 0\n",
    "for real_class, category in enumerate(image_classes):\n",
    "    category_dir =  os.path.join(testing_dataset,category)\n",
    "    start_time = time.time()\n",
    "    for img_name in os.listdir(category_dir):\n",
    "        img_path = os.path.join(category_dir,img_name)\n",
    "        single_image  = load_img(img_path, grayscale=False,target_size=(224, 324), color_mode='rgb')\n",
    "        img_array = image.img_to_array(single_image)/255\n",
    "        img_batch = np.expand_dims(img_array, axis=0)\n",
    "        prediction = model.predict_classes(img_batch)[0]\n",
    "        real_calss_list.append(real_class)\n",
    "        prediction_class_list.append(prediction)\n",
    "        count = count + 1\n",
    "        if count%100 == 0:\n",
    "            print(count,' images prediction completed. Time taken {:.2f} s'.format(time.time()-start_time))\n",
    "            start_time = time.time()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41e8c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'real':real_calss_list,'prediction':prediction_class_list}\n",
    "df = pd.DataFrame(df_dict)\n",
    "df.to_excel('model_1_realVs_pred.xlsx',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a68f1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Bagda       0.87      1.00      0.93       569\n",
      "       Deshi       1.00      0.98      0.99       874\n",
      "       Golda       0.99      0.94      0.97      1067\n",
      "      Horina       0.95      0.95      0.95       612\n",
      "\n",
      "    accuracy                           0.96      3122\n",
      "   macro avg       0.95      0.97      0.96      3122\n",
      "weighted avg       0.97      0.96      0.96      3122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"Bagda\",\"Deshi\",\"Golda\",'Horina']\n",
    "print(classification_report(real_calss_list, prediction_class_list, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvAI",
   "language": "python",
   "name": "venvai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
