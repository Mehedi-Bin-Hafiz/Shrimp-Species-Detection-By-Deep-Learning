{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c5d1b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "from keras.preprocessing.image import load_img\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from matplotlib import  pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "from skimage import io\n",
    "import time\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras \n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "model = keras.models.load_model('../Shrimp_model_2.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b2e03a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bagda', 'deshi', 'golda', 'horina']\n",
      "total class  4\n"
     ]
    }
   ],
   "source": [
    "testing_dataset = 'F:\\\\Research database\\\\Shrimp Recognition\\\\testing\\\\' \n",
    "main_classes = os.listdir(testing_dataset) \n",
    "print(main_classes)\n",
    "len_main_classes = len(main_classes)\n",
    "print('total class ',len_main_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de3de270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images prediction completed. Time taken 138.21 s\n",
      "200  images prediction completed. Time taken 113.34 s\n",
      "300  images prediction completed. Time taken 116.04 s\n",
      "400  images prediction completed. Time taken 67.25 s\n",
      "500  images prediction completed. Time taken 98.15 s\n",
      "600  images prediction completed. Time taken 34.81 s\n",
      "700  images prediction completed. Time taken 115.88 s\n",
      "800  images prediction completed. Time taken 113.87 s\n",
      "900  images prediction completed. Time taken 112.28 s\n",
      "1000  images prediction completed. Time taken 112.84 s\n",
      "1100  images prediction completed. Time taken 111.98 s\n",
      "1200  images prediction completed. Time taken 91.40 s\n",
      "1300  images prediction completed. Time taken 68.22 s\n",
      "1400  images prediction completed. Time taken 71.49 s\n",
      "1500  images prediction completed. Time taken 20.27 s\n",
      "1600  images prediction completed. Time taken 39.04 s\n",
      "1700  images prediction completed. Time taken 32.57 s\n",
      "1800  images prediction completed. Time taken 36.07 s\n",
      "1900  images prediction completed. Time taken 39.10 s\n",
      "2000  images prediction completed. Time taken 33.52 s\n",
      "2100  images prediction completed. Time taken 32.40 s\n",
      "2200  images prediction completed. Time taken 13.43 s\n",
      "2300  images prediction completed. Time taken 22.25 s\n",
      "2400  images prediction completed. Time taken 36.62 s\n",
      "2500  images prediction completed. Time taken 32.29 s\n",
      "2600  images prediction completed. Time taken 29.38 s\n",
      "2700  images prediction completed. Time taken 29.43 s\n",
      "2800  images prediction completed. Time taken 36.06 s\n",
      "2900  images prediction completed. Time taken 20.77 s\n",
      "3000  images prediction completed. Time taken 17.90 s\n",
      "3100  images prediction completed. Time taken 15.20 s\n"
     ]
    }
   ],
   "source": [
    "real_calss_list = list()\n",
    "prediction_class_list = list()\n",
    "image_classes = os.listdir(testing_dataset)\n",
    "count = 0\n",
    "for real_class, category in enumerate(image_classes):\n",
    "    category_dir =  os.path.join(testing_dataset,category)\n",
    "    start_time = time.time()\n",
    "    for img_name in os.listdir(category_dir):\n",
    "        img_path = os.path.join(category_dir,img_name)\n",
    "        single_image  = load_img(img_path, grayscale=False,target_size=(224, 224), color_mode='rgb')\n",
    "        img_array = image.img_to_array(single_image)/255\n",
    "        img_batch = np.expand_dims(img_array, axis=0)\n",
    "        prediction = model.predict_classes(img_batch)[0]\n",
    "        real_calss_list.append(real_class)\n",
    "        prediction_class_list.append(prediction)\n",
    "        count = count + 1\n",
    "        if count%100 == 0:\n",
    "            print(count,' images prediction completed. Time taken {:.2f} s'.format(time.time()-start_time))\n",
    "            start_time = time.time()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41e8c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'real':real_calss_list,'prediction':prediction_class_list}\n",
    "df = pd.DataFrame(df_dict)\n",
    "df.to_excel('model_2_realVs_pred.xlsx',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a68f1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Bagda       0.99      0.93      0.96       569\n",
      "       Deshi       1.00      0.97      0.98       874\n",
      "       Golda       0.94      0.97      0.95      1067\n",
      "      Horina       0.95      0.98      0.97       612\n",
      "\n",
      "    accuracy                           0.97      3122\n",
      "   macro avg       0.97      0.96      0.97      3122\n",
      "weighted avg       0.97      0.97      0.97      3122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"Bagda\",\"Deshi\",\"Golda\",'Horina']\n",
    "print(classification_report(real_calss_list, prediction_class_list, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvAI",
   "language": "python",
   "name": "venvai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
